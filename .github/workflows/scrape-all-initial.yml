name: STEP 1 - Download TUTTO e genera JSON per anni

on:
  workflow_dispatch:
    inputs:
      year:
        description: 'Anno da scaricare (2025, 2024, 2023, 2022, 2021, 2020 o vuoto per tutti)'
        required: false
        default: ''
      max_pages:
        description: 'Numero massimo pagine (0 = tutte). Funziona anche con year per test limitati'
        required: false
        default: '0'

# Previene conflitti: solo un workflow scraping alla volta
concurrency:
  group: scraping-workflows
  cancel-in-progress: false  # Nuovi workflow aspettano invece di cancellare quelli in corso

jobs:
  scrape-all:
    runs-on: ubuntu-latest
    timeout-minutes: 600  # 10 ore max per download completo
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.inputs.branch || github.ref }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Chrome
        run: |
          wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo apt-get install -y ./google-chrome-stable_current_amd64.deb
          rm google-chrome-stable_current_amd64.deb

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: STEP 1.1 - Download HTML (CIVILE - QUINTA)
        run: |
          YEAR="${{ github.event.inputs.year }}"
          MAX_PAGES="${{ github.event.inputs.max_pages || '0' }}"

          # Caso 1: Anno specifico
          if [ -n "$YEAR" ]; then
            echo "ðŸ“¥ Download anno $YEAR (CIVILE - QUINTA SEZIONE)"

            # Calcola pagine stimate per anno
            case "$YEAR" in
              2025) EST_PAGES=1156; EST_TIME="~1.2 ore" ;;
              2024) EST_PAGES=1097; EST_TIME="~1.1 ore" ;;
              2023) EST_PAGES=1137; EST_TIME="~1.2 ore" ;;
              2022) EST_PAGES=902; EST_TIME="~1.0 ore" ;;
              2021) EST_PAGES=1203; EST_TIME="~1.2 ore" ;;
              2020) EST_PAGES=95; EST_TIME="~10 min" ;;
              *) EST_PAGES="???"; EST_TIME="???" ;;
            esac

            # Se MAX_PAGES specificato, usa quello, altrimenti tutte
            if [ "$MAX_PAGES" != "0" ]; then
              echo "ðŸ“¥ Download $MAX_PAGES pagine per anno $YEAR (test limitato)"
              echo "â±ï¸  Tempo stimato: ~$((MAX_PAGES * 2 / 60)) minuti (delay 2.0s/pagina)"
              python3 scraper/scripts/1_download_html.py \
                --year-filter $YEAR \
                --pages $MAX_PAGES \
                --output scraper/data/html
            else
              echo "â±ï¸  Tempo stimato: $EST_TIME (~$EST_PAGES pagine)"
              python3 scraper/scripts/1_download_html.py \
                --year-filter $YEAR \
                --pages 99999 \
                --output scraper/data/html
            fi

          # Caso 2: Tutte le pagine (tutti gli anni)
          elif [ "$MAX_PAGES" = "0" ]; then
            echo "ðŸ“¥ Download TUTTI gli anni (~5591 pagine totali)..."
            echo "âš ï¸  ATTENZIONE: Supera limite 6 ore GitHub Actions!"
            echo "â„¹ï¸  Consiglio: usa parametro 'year' per scaricare un anno alla volta"
            python3 scraper/scripts/1_download_html.py \
              --pages 99999 \
              --output scraper/data/html
          else
            echo "ðŸ“¥ Download max $MAX_PAGES pagine..."
            echo "â±ï¸  Tempo stimato: ~$((MAX_PAGES * 2 / 60)) minuti (delay 2.0s/pagina)"
            python3 scraper/scripts/1_download_html.py \
              --pages $MAX_PAGES \
              --output scraper/data/html
          fi

      - name: STEP 1.2 - Parse HTML e genera TUTTI i JSON per anno
        run: |
          echo "ðŸ” Parsing HTML â†’ JSON per TUTTI gli anni..."
          echo "ðŸ“Š Strategia efficiente: UN download, TUTTI i JSON!"
          python3 scraper/scripts/2_parse_html_to_json.py \
            --html-dir scraper/data/html \
            --all-years \
            --delete-html

      - name: Check for changes
        id: check_changes
        run: |
          git status
          if [ -n "$(git status --porcelain)" ]; then
            echo "changes=true" >> $GITHUB_OUTPUT
            echo "âœ… Changes detected"
          else
            echo "changes=false" >> $GITHUB_OUTPUT
            echo "â„¹ï¸  No changes to commit"
          fi

      - name: Commit and push changes
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Add tutti i JSON generati
          git add metadata/metadata_cassazione_*.json

          # Commit
          git commit -m "STEP 1 completato: Tutti i JSON per anno generati - $(date +'%Y-%m-%d %H:%M UTC')" \
                     -m "- Download completo HTML CIVILE - QUINTA" \
                     -m "- JSON separati per ogni anno: 2020, 2021, 2022, 2023, 2024, 2025" \
                     -m "- HTML cancellati dopo parsing" \
                     -m "- Prossimo step: STEP 2 per scaricare PDF anno per anno"

          # Pull con rebase prima di pushare (evita conflitti se il branch Ã¨ stato aggiornato)
          echo "ðŸ”„ Sincronizzazione con remote..."
          git pull --rebase origin ${{ github.ref_name }} || echo "âš ï¸  Nessun conflitto da risolvere"

          # Push
          echo "ðŸ“¤ Push al remote..."
          git push

      - name: Summary
        if: always()
        run: |
          echo "## ðŸ“Š STEP 1 - Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### JSON Generati:" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          for json_file in metadata/metadata_cassazione_*.json; do
            if [ -f "$json_file" ]; then
              YEAR=$(basename "$json_file" | sed 's/metadata_cassazione_//;s/.json//')
              TOTAL=$(python3 -c "import json; data=json.load(open('$json_file')); print(data['metadata']['total_sentences'])")
              echo "- **$YEAR**: $TOTAL sentenze" >> $GITHUB_STEP_SUMMARY
            fi
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… STEP 1 completato!" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“ Prossimo: usa workflow 'STEP 2' per scaricare PDF di un anno specifico" >> $GITHUB_STEP_SUMMARY
